{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "spoken-doctor",
   "metadata": {},
   "source": [
    "# The script I use to start the machine learning process. It is by no means pretty. Pieces come from different tutorials so it is not uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "provincial-willow",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pickle\n",
    "\n",
    "import seqvec\n",
    "from allennlp.commands.elmo import ElmoEmbedder\n",
    "from pathlib import Path\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accessible-settlement",
   "metadata": {},
   "source": [
    "# The following is for one-hot encoding the positions in the sugars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exciting-september",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = ['carboxylic', 'terminal alcohol', 'aldehyde', 'terminal phosphate', 'none', 'R alcohol', 'R phosphate', 'S alcohol', 'S phosphate', 'deoxy', 'ketone']\n",
    "values = array(configs)\n",
    "print(values)\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(values)\n",
    "print(integer_encoded)\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "print(onehot_encoded)\n",
    "inverted = label_encoder.inverse_transform([argmax(onehot_encoded[0,:])])\n",
    "print(inverted)\n",
    "\n",
    "fulltable = pd.read_csv(\"LigandRDFeatures.csv\")\n",
    "positions = ['Pos1', 'Pos2', 'Pos3', 'Pos4', 'Pos5', 'Pos6']\n",
    "for pos in positions:\n",
    "    tmp = list(fulltable[pos])\n",
    "    tmplist = []\n",
    "    for item in tmp:\n",
    "        i = list(values).index(item)\n",
    "        j = onehot_encoded[i]\n",
    "        tmplist.append(j)\n",
    "    fulltable['%s_array' % (pos)] = tmplist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "czech-filename",
   "metadata": {},
   "source": [
    "# The following is the one-hot encoding for the number of carbons in the sugar. It is nearly identical in form to the one-hot encoding above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "native-weekend",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = ['C2', 'C3', 'C4', 'C5', 'C6']\n",
    "values = array(configs)\n",
    "print(values)\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(values)\n",
    "print(integer_encoded)\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "print(onehot_encoded)\n",
    "inverted = label_encoder.inverse_transform([argmax(onehot_encoded[0,:])])\n",
    "print(inverted)\n",
    "\n",
    "\n",
    "tmp = list(fulltable['Carbons'])\n",
    "tmplist = []\n",
    "for item in tmp:\n",
    "    i = list(values).index(item)\n",
    "    j = onehot_encoded[i]\n",
    "    tmplist.append(j)\n",
    "fulltable['Carbons_array'] = tmplist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bottom-particular",
   "metadata": {},
   "source": [
    "# This is to join the ligand features for each ligand and to save them in a pickle file for ease of use later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "furnished-headquarters",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['carboxylic' 'terminal alcohol' 'aldehyde' 'terminal phosphate' 'none'\n",
      " 'R alcohol' 'R phosphate' 'S alcohol' 'S phosphate' 'deoxy' 'ketone']\n",
      "[ 5  9  4 10  8  0  1  2  3  6  7]\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]]\n",
      "['carboxylic']\n",
      "['C2' 'C3' 'C4' 'C5' 'C6']\n",
      "[0 1 2 3 4]\n",
      "[[1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1.]]\n",
      "['C2']\n"
     ]
    }
   ],
   "source": [
    "fullligand_list = []\n",
    "for index, row in fulltable.iterrows():\n",
    "    t = np.concatenate((row['Carbons_array'],row['TPSA'],row['ASA'],row['HBA'],row['HBD'],row['RotBond'],row['LogP'],row['Pos1_array'],row['Pos2_array'],row['Pos3_array'],row['Pos4_array'],row['Pos5_array'],row['Pos6_array']),axis = None)\n",
    "    fullligand_list.append(t)\n",
    "fulltable['FullLigand'] = fullligand_list\n",
    "\n",
    "ligembed = fulltable['FullLigand'].tolist()\n",
    "pickle_out = open(\"Ligand_embeddings_040621.pickle\", \"wb\")\n",
    "pickle.dump(ligembed, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numeric-valuation",
   "metadata": {},
   "source": [
    "# The following cell is to create the seqvec embeddings for each sequence. I was able to download the model from the seqvec github. The two files needed are weights.hdf5 and options.json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dependent-sequence",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Creating dictionary of uniprot codes with fasta seqs\n",
    "import os\n",
    "import pandas as pd\n",
    "import seqvec\n",
    "import numpy as np\n",
    "from allennlp.commands.elmo import ElmoEmbedder\n",
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "FastaDict = {}\n",
    "for fastafile in os.listdir('../../Fastas/'):\n",
    "    tmp = []\n",
    "    for line in open('../../Fastas/'+fastafile):\n",
    "        if line[0] == '>':\n",
    "            pass\n",
    "        else:\n",
    "            line = line.rstrip('\\n')\n",
    "            tmp.append(line)\n",
    "    tmp = ''.join(tmp)\n",
    "    FastaDict['%s' % (fastafile[:-6])] = tmp\n",
    "\n",
    "\n",
    "model_dir = Path('../../../../ML_Learning/model')\n",
    "weights = model_dir / 'weights.hdf5'\n",
    "options = model_dir / 'options.json'\n",
    "embedder = ElmoEmbedder(options, weights, cuda_device=-1)\n",
    "UniList = []\n",
    "EmbedList = []\n",
    "\n",
    "for uniprot in FastaDict:\n",
    "    UniList.append(uniprot)\n",
    "    seq = FastaDict[uniprot]\n",
    "    embedding = embedder.embed_sentence(list(seq))\n",
    "    protein_embd = torch.tensor(embedding).sum(dim=0).mean(dim=0)\n",
    "    Full_embed = protein_embd.numpy()\n",
    "\n",
    "    EmbedList.append(Full_embed)\n",
    "        \n",
    "FullProtEmbed = pd.DataFrame()\n",
    "FullProtEmbed['Uniprot'] = UniList\n",
    "FullProtEmbed['Embedding'] = EmbedList\n",
    "\n",
    "import pickle\n",
    "pickle_out = open(\"Protein_embeddings_040621.pickle\", \"wb\")\n",
    "pickle.dump(EmbedList, pickle_out)\n",
    "pickle_out.close()\n",
    "FullProtEmbed['Uniprot'].to_csv('UniprotListing.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valid-boring",
   "metadata": {},
   "source": [
    "# This combines each protein-ligand pair with the appropriate embeddings and saves the full features to a pickle file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "remarkable-vienna",
   "metadata": {},
   "outputs": [],
   "source": [
    "ProteinList = UniList\n",
    "LigandList = list(fulltable['#'])\n",
    "ProtEmbeddings = EmbedList\n",
    "LigandEmbeddings = fullligand_list\n",
    "ActivityTable = pd.read_csv('../../Activity_Table_02Hit.csv')\n",
    "\n",
    "EmbeddingList = []\n",
    "ActivityList = []\n",
    "IdentityList = []\n",
    "\n",
    "protcount = 0\n",
    "\n",
    "LigandList.remove(147)\n",
    "for uniprot in ProteinList:\n",
    "    protembed = ProtEmbeddings[protcount]\n",
    "    ligcount = 0\n",
    "    for ligand in LigandList:\n",
    "        lignum = LigandList[ligcount]\n",
    "\n",
    "        ligembed = LigandEmbeddings[ligcount]\n",
    "        entryembed = np.concatenate((protembed,ligembed),axis=None)\n",
    "        ligcount += 1\n",
    "        IdentityList.append('%s_%s' % (uniprot,ligand))\n",
    "        EmbeddingList.append(entryembed)\n",
    "        Activity = ActivityTable.loc[ActivityTable.UniprotID == uniprot, str(lignum)].values[0]\n",
    "        ActivityList.append(Activity)\n",
    "    protcount += 1\n",
    "\n",
    "pickle_out = open(\"PairEmbeddings_040621.pickle\", \"wb\")\n",
    "pickle.dump(EmbeddingList, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "d = {'Pair_Identity': IdentityList, 'Activity_by_mean': ActivityList}\n",
    "df = pd.DataFrame(d)\n",
    "df.to_csv('Identity_Activity_040621.csv')    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explicit-loading",
   "metadata": {},
   "source": [
    "# The following is to load in the pickle file and the activity csv file to use for machine learning. This is for when you have created the embeddings previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "violent-negative",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open(\"PairEmbeddings_040621.pickle\" , \"rb\")\n",
    "EmbeddingList = pickle.load(pickle_in)\n",
    "\n",
    "df = pd.read_csv('Identity_Activity_040621.csv')\n",
    "ActivityList = df['Activity_by_mean'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "young-bullet",
   "metadata": {},
   "source": [
    "# These are the imports and the splitting of the data into training and validation. I am sorry for import inconsistencies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expressed-vertex",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import scipy\n",
    "import numpy\n",
    "import matplotlib\n",
    "import pandas\n",
    "import sklearn\n",
    "from pandas import read_csv\n",
    "from pandas.plotting import scatter_matrix\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "import sklearn.metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import neural_network\n",
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform \n",
    "from numpy import arange\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "X_train, X_validation, Y_train, Y_validation = train_test_split(EmbeddingList, ActivityList, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rational-mexican",
   "metadata": {},
   "source": [
    "# This is to test a variety of default methods and compare the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "harmful-bryan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.481128 (0.018150)\n",
      "LDA: 0.532281 (0.011386)\n",
      "KNN: 0.424668 (0.024565)\n",
      "CART: 0.533984 (0.014988)\n",
      "NB: 0.394714 (0.018511)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tim\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Users\\Tim\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Users\\Tim\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Users\\Tim\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Users\\Tim\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Users\\Tim\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Users\\Tim\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Users\\Tim\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Users\\Tim\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Users\\Tim\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QDA: 0.376002 (0.011634)\n",
      "RDG: 0.465706 (0.019636)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tim\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Tim\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Tim\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Tim\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Tim\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Tim\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Tim\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Tim\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Tim\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPNN: 0.642368 (0.028261)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tim\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Spot Check Algorithms\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression(solver='liblinear', multi_class='ovr')))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "#models.append(('SVM', SVC(gamma='auto')))\n",
    "models.append(('QDA', sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis()))\n",
    "models.append(('RDG', sklearn.linear_model.RidgeClassifier()))\n",
    "models.append(('MLPNN', sklearn.neural_network.MLPClassifier()))\n",
    "\n",
    "              \n",
    "#evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    kfold=StratifiedKFold(n_splits=10, random_state=1, shuffle=True)\n",
    "    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring='f1')\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    print('%s: %f (%f)' % (name, cv_results.mean(), cv_results.std()))\n",
    "    \n",
    "pyplot.boxplot(results, labels=names)\n",
    "pyplot.title('Algorithm Comparison')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distributed-grill",
   "metadata": {},
   "source": [
    "# Train a model on the full training set and test on the validation set. Variety of metrics printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "laden-cover",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8653100775193798\n",
      "[[1565  154]\n",
      " [ 124  221]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92      1719\n",
      "           1       0.59      0.64      0.61       345\n",
      "\n",
      "    accuracy                           0.87      2064\n",
      "   macro avg       0.76      0.78      0.77      2064\n",
      "weighted avg       0.87      0.87      0.87      2064\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tim\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#Make predictions on validation dataset\n",
    "model = sklearn.neural_network.MLPClassifier(hidden_layer_sizes=(100,100))\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "\n",
    "#Evaluate predictions\n",
    "print(sklearn.metrics.accuracy_score(Y_validation, predictions))\n",
    "print(confusion_matrix(Y_validation, predictions))\n",
    "print(classification_report(Y_validation, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indie-spanking",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning of the MLP Classifier. The n_iter indicates how many parameters are sampled, so that would need to be much higher to be useful. GridSearchCV is an alternative to RandomizedSearchCV where it will go through parameter options exhaustively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "guilty-velvet",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tim\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Tim\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Tim\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Tim\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Tim\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Tim\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Tim\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Tim\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Tim\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Tim\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top f1: 0.526\n",
      "Config: {'activation': 'identity', 'alpha': 0.3464965142407303, 'hidden_layer_sizes': (386, 256), 'learning_rate': 'adaptive', 'solver': 'lbfgs'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tim\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "model = sklearn.neural_network.MLPClassifier()\n",
    "\n",
    "parameter_space = {\n",
    "    'hidden_layer_sizes': [(sp_randint.rvs(100,600,1),sp_randint.rvs(100,600,1),), \n",
    "                                          (sp_randint.rvs(100,600,1),)],\n",
    "    'activation': ['tanh', 'identity', 'relu', 'logistic'],\n",
    "    'solver': ['sgd', 'adam', 'lbfgs'],\n",
    "    'alpha': uniform(0.0001, 0.9),\n",
    "    'learning_rate': ['constant','adaptive']}\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=1, random_state=42)\n",
    "\n",
    "search = sklearn.model_selection.RandomizedSearchCV(model,parameter_space, scoring='f1',cv=cv, n_iter=1)\n",
    "results = search.fit(X_train, Y_train)\n",
    "print('top f1: %.3f' % results.best_score_)\n",
    "print('Config: %s' % results.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "informative-lounge",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "following-enough",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
